{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 100 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   rev_Mean          99643 non-null   float64\n",
      " 1   mou_Mean          99643 non-null   float64\n",
      " 2   totmrc_Mean       99643 non-null   float64\n",
      " 3   da_Mean           99643 non-null   float64\n",
      " 4   ovrmou_Mean       99643 non-null   float64\n",
      " 5   ovrrev_Mean       99643 non-null   float64\n",
      " 6   vceovr_Mean       99643 non-null   float64\n",
      " 7   datovr_Mean       99643 non-null   float64\n",
      " 8   roam_Mean         99643 non-null   float64\n",
      " 9   change_mou        99109 non-null   float64\n",
      " 10  change_rev        99109 non-null   float64\n",
      " 11  drop_vce_Mean     100000 non-null  float64\n",
      " 12  drop_dat_Mean     100000 non-null  float64\n",
      " 13  blck_vce_Mean     100000 non-null  float64\n",
      " 14  blck_dat_Mean     100000 non-null  float64\n",
      " 15  unan_vce_Mean     100000 non-null  float64\n",
      " 16  unan_dat_Mean     100000 non-null  float64\n",
      " 17  plcd_vce_Mean     100000 non-null  float64\n",
      " 18  plcd_dat_Mean     100000 non-null  float64\n",
      " 19  recv_vce_Mean     100000 non-null  float64\n",
      " 20  recv_sms_Mean     100000 non-null  float64\n",
      " 21  comp_vce_Mean     100000 non-null  float64\n",
      " 22  comp_dat_Mean     100000 non-null  float64\n",
      " 23  custcare_Mean     100000 non-null  float64\n",
      " 24  ccrndmou_Mean     100000 non-null  float64\n",
      " 25  cc_mou_Mean       100000 non-null  float64\n",
      " 26  inonemin_Mean     100000 non-null  float64\n",
      " 27  threeway_Mean     100000 non-null  float64\n",
      " 28  mou_cvce_Mean     100000 non-null  float64\n",
      " 29  mou_cdat_Mean     100000 non-null  float64\n",
      " 30  mou_rvce_Mean     100000 non-null  float64\n",
      " 31  owylis_vce_Mean   100000 non-null  float64\n",
      " 32  mouowylisv_Mean   100000 non-null  float64\n",
      " 33  iwylis_vce_Mean   100000 non-null  float64\n",
      " 34  mouiwylisv_Mean   100000 non-null  float64\n",
      " 35  peak_vce_Mean     100000 non-null  float64\n",
      " 36  peak_dat_Mean     100000 non-null  float64\n",
      " 37  mou_peav_Mean     100000 non-null  float64\n",
      " 38  mou_pead_Mean     100000 non-null  float64\n",
      " 39  opk_vce_Mean      100000 non-null  float64\n",
      " 40  opk_dat_Mean      100000 non-null  float64\n",
      " 41  mou_opkv_Mean     100000 non-null  float64\n",
      " 42  mou_opkd_Mean     100000 non-null  float64\n",
      " 43  drop_blk_Mean     100000 non-null  float64\n",
      " 44  attempt_Mean      100000 non-null  float64\n",
      " 45  complete_Mean     100000 non-null  float64\n",
      " 46  callfwdv_Mean     100000 non-null  float64\n",
      " 47  callwait_Mean     100000 non-null  float64\n",
      " 48  churn             100000 non-null  int64  \n",
      " 49  months            100000 non-null  int64  \n",
      " 50  uniqsubs          100000 non-null  int64  \n",
      " 51  actvsubs          100000 non-null  int64  \n",
      " 52  new_cell          100000 non-null  object \n",
      " 53  crclscod          100000 non-null  object \n",
      " 54  asl_flag          100000 non-null  object \n",
      " 55  totcalls          100000 non-null  int64  \n",
      " 56  totmou            100000 non-null  float64\n",
      " 57  totrev            100000 non-null  float64\n",
      " 58  adjrev            100000 non-null  float64\n",
      " 59  adjmou            100000 non-null  float64\n",
      " 60  adjqty            100000 non-null  int64  \n",
      " 61  avgrev            100000 non-null  float64\n",
      " 62  avgmou            100000 non-null  float64\n",
      " 63  avgqty            100000 non-null  float64\n",
      " 64  avg3mou           100000 non-null  int64  \n",
      " 65  avg3qty           100000 non-null  int64  \n",
      " 66  avg3rev           100000 non-null  int64  \n",
      " 67  avg6mou           97161 non-null   float64\n",
      " 68  avg6qty           97161 non-null   float64\n",
      " 69  avg6rev           97161 non-null   float64\n",
      " 70  prizm_social_one  92612 non-null   object \n",
      " 71  area              99960 non-null   object \n",
      " 72  dualband          99999 non-null   object \n",
      " 73  refurb_new        99999 non-null   object \n",
      " 74  hnd_price         99153 non-null   float64\n",
      " 75  phones            99999 non-null   float64\n",
      " 76  models            99999 non-null   float64\n",
      " 77  hnd_webcap        89811 non-null   object \n",
      " 78  truck             98268 non-null   float64\n",
      " 79  rv                98268 non-null   float64\n",
      " 80  ownrent           66294 non-null   object \n",
      " 81  lor               69810 non-null   float64\n",
      " 82  dwlltype          68091 non-null   object \n",
      " 83  marital           98268 non-null   object \n",
      " 84  adults            76981 non-null   float64\n",
      " 85  infobase          77921 non-null   object \n",
      " 86  income            74564 non-null   float64\n",
      " 87  numbcars          50634 non-null   float64\n",
      " 88  HHstatin          62077 non-null   object \n",
      " 89  dwllsize          61692 non-null   object \n",
      " 90  forgntvl          98268 non-null   float64\n",
      " 91  ethnic            98268 non-null   object \n",
      " 92  kid0_2            98268 non-null   object \n",
      " 93  kid3_5            98268 non-null   object \n",
      " 94  kid6_10           98268 non-null   object \n",
      " 95  kid11_15          98268 non-null   object \n",
      " 96  kid16_17          98268 non-null   object \n",
      " 97  creditcd          98268 non-null   object \n",
      " 98  eqpdays           99999 non-null   float64\n",
      " 99  Customer_ID       100000 non-null  int64  \n",
      "dtypes: float64(69), int64(10), object(21)\n",
      "memory usage: 76.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/dataset.csv', delimiter=';', decimal=',')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23,9975</td>\n",
       "      <td>219,25</td>\n",
       "      <td>22,5</td>\n",
       "      <td>0,2475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-157,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57,4925</td>\n",
       "      <td>482,75</td>\n",
       "      <td>37,425</td>\n",
       "      <td>0,2475</td>\n",
       "      <td>22,75</td>\n",
       "      <td>9,1</td>\n",
       "      <td>9,1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>532,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16,99</td>\n",
       "      <td>10,25</td>\n",
       "      <td>16,99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>7,5</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1,5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55,23</td>\n",
       "      <td>570,5</td>\n",
       "      <td>71,98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38,5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rev_Mean mou_Mean totmrc_Mean da_Mean ovrmou_Mean ovrrev_Mean vceovr_Mean  \\\n",
       "0  23,9975   219,25        22,5  0,2475           0           0           0   \n",
       "1  57,4925   482,75      37,425  0,2475       22,75         9,1         9,1   \n",
       "2    16,99    10,25       16,99       0           0           0           0   \n",
       "3       38      7,5          38       0           0           0           0   \n",
       "4    55,23    570,5       71,98       0           0           0           0   \n",
       "\n",
       "  datovr_Mean roam_Mean change_mou  ... forgntvl ethnic kid0_2 kid3_5 kid6_10  \\\n",
       "0           0         0    -157,25  ...      0.0      N      U      U       U   \n",
       "1           0         0     532,25  ...      0.0      Z      U      U       U   \n",
       "2           0         0      -4,25  ...      0.0      N      U      Y       U   \n",
       "3           0         0       -1,5  ...      0.0      U      Y      U       U   \n",
       "4           0         0       38,5  ...      0.0      I      U      U       U   \n",
       "\n",
       "  kid11_15 kid16_17 creditcd eqpdays Customer_ID  \n",
       "0        U        U        Y   361.0     1000001  \n",
       "1        U        U        Y   240.0     1000002  \n",
       "2        U        U        Y  1504.0     1000003  \n",
       "3        U        U        Y  1812.0     1000004  \n",
       "4        U        U        Y   434.0     1000005  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_missings(df, miss_pct_th = 33, threshold_num = 0.1, threshold_chi=0.05):\n",
    "    \n",
    "    missings_pct = (df.isnull().sum()/len(df)) * 100\n",
    "    \n",
    "    # Eliminamos directamente las columnas con un % de missing superior al 33%\n",
    "    df = df.drop(columns = missings_pct[missings_pct > miss_pct_th].index)\n",
    "    \n",
    "    # Las columnas con missings entre 0 y 33 las dividiremos en 2 grupos, numéricas y categóricas:\n",
    "    \n",
    "    columns_missings = missings_pct[(missings_pct < miss_pct_th) & (missings_pct > 0)].index.tolist()\n",
    "    df_missings = df[columns_missings + ['churn']]\n",
    "    \n",
    "    df_num_missings = df_missings.select_dtypes(include=[np.number])\n",
    "    df_cat_missings = df_missings.select_dtypes(include=[object])\n",
    "    \n",
    "    # Numéricas\n",
    "    print(\"Las columnas numéricas con nulos son las siguientes:\\n\", df_num_missings.index )\n",
    "    \n",
    "    corr_with_churn = df_num_missings.corrwith(df_num_missings['churn'])\n",
    "    \n",
    "    cols_to_keep = corr_with_churn[abs(corr_with_churn) >= threshold_num].index.tolist()\n",
    "    \n",
    "    print(\"Se van a imputar con la mediana las siguientes columnas:\\n\", cols_to_keep)\n",
    "\n",
    "    \n",
    "    if 'churn' not in cols_to_keep:\n",
    "        cols_to_keep.append('churn')\n",
    "        \n",
    "    #print(cols_to_keep)\n",
    "\n",
    "    for col in cols_to_keep:\n",
    "        if col != 'churn':\n",
    "            median = df_num_missings[col].median()\n",
    "            df[col] = df[col].fillna(median)\n",
    "    \n",
    "    cols_to_drop = corr_with_churn[abs(corr_with_churn) < threshold_num].index.tolist()\n",
    "    \n",
    "    print(\"Se van a dropear las siguientes por baja correlación con la columna churn:\\n\", cols_to_drop)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    # Categóricas\n",
    "    \n",
    "    print(\"Las columnas numéricas con nulos son las siguientes:\\n\", df_cat_missings.index )\n",
    "\n",
    "    \n",
    "    if 'churn' not in df_cat_missings.columns:\n",
    "        df_cat_missings['churn'] = df['churn']\n",
    "        \n",
    "    def chi2_test(cols, target):\n",
    "        cont_table = pd.crosstab(cols, target)\n",
    "        res = chi2_contingency(cont_table)\n",
    "        return res.pvalue\n",
    "    \n",
    "    chi2_res = df_cat_missings.apply(lambda x: chi2_test(x, df['churn'])).sort_values()\n",
    "    \n",
    "    #print(chi2_res)\n",
    "    \n",
    "    cols_to_keep = chi2_res[chi2_res <= threshold_chi].index.tolist()\n",
    "    \n",
    "    print(\"Se van a imputar con la moda las siguientes columnas:\\n\", cols_to_keep)\n",
    "    \n",
    "    if 'churn' not in cols_to_keep:\n",
    "        cols_to_keep.append('churn')\n",
    "    \n",
    "    for col in cols_to_keep:\n",
    "        if col != 'churn':\n",
    "            mode = df_cat_missings[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode)\n",
    "            \n",
    "    cols_to_drop = chi2_res[chi2_res > threshold_chi].index.tolist()\n",
    "    \n",
    "    print(\"Se van a dropear las siguientes por baja correlación con la columna churn:\\n\", cols_to_drop)\n",
    "    \n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos directamente las columnas que tienen unos valores de missing mayores al 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las columnas numéricas con nulos son las siguientes:\n",
      " RangeIndex(start=0, stop=100000, step=1)\n",
      "Se van a imputar con la mediana las siguientes columnas:\n",
      " ['hnd_price', 'eqpdays', 'churn']\n",
      "Se van a dropear las siguientes por baja correlación con la columna churn:\n",
      " ['rev_Mean', 'mou_Mean', 'totmrc_Mean', 'da_Mean', 'ovrmou_Mean', 'ovrrev_Mean', 'vceovr_Mean', 'datovr_Mean', 'roam_Mean', 'change_mou', 'change_rev', 'avg6mou', 'avg6qty', 'avg6rev', 'phones', 'models', 'truck', 'rv', 'lor', 'adults', 'income', 'forgntvl']\n",
      "Las columnas numéricas con nulos son las siguientes:\n",
      " RangeIndex(start=0, stop=100000, step=1)\n",
      "Se van a imputar con la moda las siguientes columnas:\n",
      " ['churn', 'hnd_webcap', 'ethnic', 'dualband', 'area', 'refurb_new', 'marital', 'prizm_social_one', 'creditcd', 'infobase', 'dwlltype', 'kid0_2']\n",
      "Se van a dropear las siguientes por baja correlación con la columna churn:\n",
      " ['kid3_5', 'kid16_17', 'kid11_15', 'kid6_10']\n"
     ]
    }
   ],
   "source": [
    "data = correct_missings(data)\n",
    "\n",
    "data.to_csv('../data/data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = data[data.columns.difference(['churn'])]\n",
    "y = data['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['S', 'V'] in column 2 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ZF'] in column 2 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [    nan 0.5709  0.51095     nan     nan]\n",
      "Mean Cross-Validation Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 371, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 89, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 211, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 600, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1076, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 885, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1290, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1024, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 214, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['C'] in column 6 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "OHE = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "RFC = RandomForestClassifier(random_state=77)\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "num_cols = X_train.select_dtypes(include = ['int64', 'float64']).columns\n",
    "\n",
    "transformer = ColumnTransformer([('cat', OHE, cat_cols), ('num', scaler, num_cols)])\n",
    "\n",
    "pipe = Pipeline([(\"preprocessing\", transformer), (\"classifier\", RFC)])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "\n",
    "print(f\"Mean Cross-Validation Score: {cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
