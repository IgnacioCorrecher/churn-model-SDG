{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 100 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   rev_Mean          99643 non-null   float64\n",
      " 1   mou_Mean          99643 non-null   float64\n",
      " 2   totmrc_Mean       99643 non-null   float64\n",
      " 3   da_Mean           99643 non-null   float64\n",
      " 4   ovrmou_Mean       99643 non-null   float64\n",
      " 5   ovrrev_Mean       99643 non-null   float64\n",
      " 6   vceovr_Mean       99643 non-null   float64\n",
      " 7   datovr_Mean       99643 non-null   float64\n",
      " 8   roam_Mean         99643 non-null   float64\n",
      " 9   change_mou        99109 non-null   float64\n",
      " 10  change_rev        99109 non-null   float64\n",
      " 11  drop_vce_Mean     100000 non-null  float64\n",
      " 12  drop_dat_Mean     100000 non-null  float64\n",
      " 13  blck_vce_Mean     100000 non-null  float64\n",
      " 14  blck_dat_Mean     100000 non-null  float64\n",
      " 15  unan_vce_Mean     100000 non-null  float64\n",
      " 16  unan_dat_Mean     100000 non-null  float64\n",
      " 17  plcd_vce_Mean     100000 non-null  float64\n",
      " 18  plcd_dat_Mean     100000 non-null  float64\n",
      " 19  recv_vce_Mean     100000 non-null  float64\n",
      " 20  recv_sms_Mean     100000 non-null  float64\n",
      " 21  comp_vce_Mean     100000 non-null  float64\n",
      " 22  comp_dat_Mean     100000 non-null  float64\n",
      " 23  custcare_Mean     100000 non-null  float64\n",
      " 24  ccrndmou_Mean     100000 non-null  float64\n",
      " 25  cc_mou_Mean       100000 non-null  float64\n",
      " 26  inonemin_Mean     100000 non-null  float64\n",
      " 27  threeway_Mean     100000 non-null  float64\n",
      " 28  mou_cvce_Mean     100000 non-null  float64\n",
      " 29  mou_cdat_Mean     100000 non-null  float64\n",
      " 30  mou_rvce_Mean     100000 non-null  float64\n",
      " 31  owylis_vce_Mean   100000 non-null  float64\n",
      " 32  mouowylisv_Mean   100000 non-null  float64\n",
      " 33  iwylis_vce_Mean   100000 non-null  float64\n",
      " 34  mouiwylisv_Mean   100000 non-null  float64\n",
      " 35  peak_vce_Mean     100000 non-null  float64\n",
      " 36  peak_dat_Mean     100000 non-null  float64\n",
      " 37  mou_peav_Mean     100000 non-null  float64\n",
      " 38  mou_pead_Mean     100000 non-null  float64\n",
      " 39  opk_vce_Mean      100000 non-null  float64\n",
      " 40  opk_dat_Mean      100000 non-null  float64\n",
      " 41  mou_opkv_Mean     100000 non-null  float64\n",
      " 42  mou_opkd_Mean     100000 non-null  float64\n",
      " 43  drop_blk_Mean     100000 non-null  float64\n",
      " 44  attempt_Mean      100000 non-null  float64\n",
      " 45  complete_Mean     100000 non-null  float64\n",
      " 46  callfwdv_Mean     100000 non-null  float64\n",
      " 47  callwait_Mean     100000 non-null  float64\n",
      " 48  churn             100000 non-null  int64  \n",
      " 49  months            100000 non-null  int64  \n",
      " 50  uniqsubs          100000 non-null  int64  \n",
      " 51  actvsubs          100000 non-null  int64  \n",
      " 52  new_cell          100000 non-null  object \n",
      " 53  crclscod          100000 non-null  object \n",
      " 54  asl_flag          100000 non-null  object \n",
      " 55  totcalls          100000 non-null  int64  \n",
      " 56  totmou            100000 non-null  float64\n",
      " 57  totrev            100000 non-null  float64\n",
      " 58  adjrev            100000 non-null  float64\n",
      " 59  adjmou            100000 non-null  float64\n",
      " 60  adjqty            100000 non-null  int64  \n",
      " 61  avgrev            100000 non-null  float64\n",
      " 62  avgmou            100000 non-null  float64\n",
      " 63  avgqty            100000 non-null  float64\n",
      " 64  avg3mou           100000 non-null  int64  \n",
      " 65  avg3qty           100000 non-null  int64  \n",
      " 66  avg3rev           100000 non-null  int64  \n",
      " 67  avg6mou           97161 non-null   float64\n",
      " 68  avg6qty           97161 non-null   float64\n",
      " 69  avg6rev           97161 non-null   float64\n",
      " 70  prizm_social_one  92612 non-null   object \n",
      " 71  area              99960 non-null   object \n",
      " 72  dualband          99999 non-null   object \n",
      " 73  refurb_new        99999 non-null   object \n",
      " 74  hnd_price         99153 non-null   float64\n",
      " 75  phones            99999 non-null   float64\n",
      " 76  models            99999 non-null   float64\n",
      " 77  hnd_webcap        89811 non-null   object \n",
      " 78  truck             98268 non-null   float64\n",
      " 79  rv                98268 non-null   float64\n",
      " 80  ownrent           66294 non-null   object \n",
      " 81  lor               69810 non-null   float64\n",
      " 82  dwlltype          68091 non-null   object \n",
      " 83  marital           98268 non-null   object \n",
      " 84  adults            76981 non-null   float64\n",
      " 85  infobase          77921 non-null   object \n",
      " 86  income            74564 non-null   float64\n",
      " 87  numbcars          50634 non-null   float64\n",
      " 88  HHstatin          62077 non-null   object \n",
      " 89  dwllsize          61692 non-null   object \n",
      " 90  forgntvl          98268 non-null   float64\n",
      " 91  ethnic            98268 non-null   object \n",
      " 92  kid0_2            98268 non-null   object \n",
      " 93  kid3_5            98268 non-null   object \n",
      " 94  kid6_10           98268 non-null   object \n",
      " 95  kid11_15          98268 non-null   object \n",
      " 96  kid16_17          98268 non-null   object \n",
      " 97  creditcd          98268 non-null   object \n",
      " 98  eqpdays           99999 non-null   float64\n",
      " 99  Customer_ID       100000 non-null  int64  \n",
      "dtypes: float64(69), int64(10), object(21)\n",
      "memory usage: 76.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/dataset.csv', delimiter=';', decimal=',')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.9975</td>\n",
       "      <td>219.25</td>\n",
       "      <td>22.500</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-157.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.4925</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.425</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.9900</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.2300</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean  da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0   23.9975    219.25       22.500   0.2475         0.00          0.0   \n",
       "1   57.4925    482.75       37.425   0.2475        22.75          9.1   \n",
       "2   16.9900     10.25       16.990   0.0000         0.00          0.0   \n",
       "3   38.0000      7.50       38.000   0.0000         0.00          0.0   \n",
       "4   55.2300    570.50       71.980   0.0000         0.00          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  forgntvl  ethnic  \\\n",
       "0          0.0          0.0        0.0     -157.25  ...       0.0       N   \n",
       "1          9.1          0.0        0.0      532.25  ...       0.0       Z   \n",
       "2          0.0          0.0        0.0       -4.25  ...       0.0       N   \n",
       "3          0.0          0.0        0.0       -1.50  ...       0.0       U   \n",
       "4          0.0          0.0        0.0       38.50  ...       0.0       I   \n",
       "\n",
       "   kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd  eqpdays  Customer_ID  \n",
       "0       U       U        U         U         U         Y    361.0      1000001  \n",
       "1       U       U        U         U         U         Y    240.0      1000002  \n",
       "2       U       Y        U         U         U         Y   1504.0      1000003  \n",
       "3       Y       U        U         U         U         Y   1812.0      1000004  \n",
       "4       U       U        U         U         U         Y    434.0      1000005  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_missings(df, miss_pct_th = 33, threshold_num = 0.05, threshold_chi=0.05):\n",
    "    \n",
    "    missings_pct = (df.isnull().sum()/len(df)) * 100\n",
    "    \n",
    "    # Eliminamos directamente las columnas con un % de missing superior al 33%\n",
    "\n",
    "    cols_to_drop = missings_pct[(missings_pct > miss_pct_th)].index.tolist()\n",
    "    \n",
    "    print(\"Se van a dropear las siguientes por excesivos nulos:\\n\", cols_to_drop)\n",
    "\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    # Las columnas con missings entre 0 y 33 las dividiremos en 2 grupos, numéricas y categóricas:\n",
    "    \n",
    "    columns_missings = missings_pct[(missings_pct < miss_pct_th) & (missings_pct > 0)].index.tolist()\n",
    "    df_missings = df[columns_missings + ['churn']]\n",
    "    \n",
    "    df_num_missings = df_missings.select_dtypes(include=[np.number])\n",
    "    df_cat_missings = df_missings.select_dtypes(include=[object])\n",
    "    \n",
    "    # Numéricas\n",
    "    #print(\"Las columnas numéricas con nulos son las siguientes:\\n\", df_num_missings.index )\n",
    "    \n",
    "    corr_with_churn = df_num_missings.corrwith(df_num_missings['churn'])\n",
    "    \n",
    "    cols_to_keep = corr_with_churn[abs(corr_with_churn) >= threshold_num].index.tolist()\n",
    "    \n",
    "    cols_to_impute = [col for col in cols_to_keep if col != 'churn']\n",
    "\n",
    "    print(\"Se van a imputar con la mediana las siguientes columnas:\\n\", cols_to_impute)\n",
    "\n",
    "    for col in cols_to_impute:\n",
    "        median = df_num_missings[col].median()\n",
    "        df[col] = df[col].fillna(median)\n",
    "    \n",
    "    cols_to_drop = corr_with_churn[abs(corr_with_churn) < threshold_num].index.tolist()\n",
    "    \n",
    "    print(\"Se van a dropear las siguientes por baja correlación con la columna churn:\\n\", cols_to_drop)\n",
    "    \n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    # Categóricas\n",
    "    \n",
    "    if 'churn' not in df_cat_missings.columns:\n",
    "        df_cat_missings['churn'] = df['churn']\n",
    "        \n",
    "    def chi2_test(cols, target):\n",
    "        cont_table = pd.crosstab(cols, target)\n",
    "        res = chi2_contingency(cont_table)\n",
    "        return res.pvalue\n",
    "    \n",
    "    chi2_res = df_cat_missings.apply(lambda x: chi2_test(x, df['churn'])).sort_values()\n",
    "    \n",
    "    #print(chi2_res)\n",
    "    \n",
    "    cols_to_keep = chi2_res[chi2_res <= threshold_chi].index.tolist()\n",
    "\n",
    "    cols_to_impute = [col for col in cols_to_keep if col != 'churn']\n",
    "    \n",
    "    print(\"Se van a imputar con la moda las siguientes columnas:\\n\", cols_to_impute)\n",
    "    \n",
    "    for col in cols_to_impute:\n",
    "        mode = df_cat_missings[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode)\n",
    "            \n",
    "    cols_to_drop = chi2_res[chi2_res > threshold_chi].index.tolist()\n",
    "    \n",
    "    print(\"Se van a dropear las siguientes por baja correlación con la columna churn:\\n\", cols_to_drop)\n",
    "    \n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_outliers(df, outlier_rate = 3):\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "    features = df.columns.to_list()\n",
    "\n",
    "    for f in features:\n",
    "        Q1 = np.percentile(df[f],25)\n",
    "        Q3 = np.percentile(df[f],75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        low_bound = Q1 - (IQR * outlier_rate)\n",
    "        up_bound = Q3 + (IQR * outlier_rate)\n",
    "\n",
    "        median = df[f].median()\n",
    "\n",
    "        df[f] = np.where((df[f] < low_bound) | (df[f] > up_bound), median, df[f])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos directamente las columnas que tienen unos valores de missing mayores al 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se van a dropear las siguientes por excesivos nulos:\n",
      " ['rev_Mean', 'mou_Mean', 'totmrc_Mean', 'da_Mean', 'ovrmou_Mean', 'ovrrev_Mean', 'vceovr_Mean', 'datovr_Mean', 'roam_Mean', 'change_mou', 'change_rev', 'avg6mou', 'avg6qty', 'avg6rev', 'prizm_social_one', 'hnd_price', 'hnd_webcap', 'truck', 'rv', 'ownrent', 'lor', 'dwlltype', 'marital', 'adults', 'infobase', 'income', 'numbcars', 'HHstatin', 'dwllsize', 'forgntvl', 'ethnic', 'kid0_2', 'kid3_5', 'kid6_10', 'kid11_15', 'kid16_17', 'creditcd']\n",
      "Se van a imputar con la mediana las siguientes columnas:\n",
      " ['eqpdays']\n",
      "Se van a dropear las siguientes por baja correlación con la columna churn:\n",
      " ['phones', 'models']\n",
      "Se van a imputar con la moda las siguientes columnas:\n",
      " ['dualband', 'area', 'refurb_new']\n",
      "Se van a dropear las siguientes por baja correlación con la columna churn:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "data.drop([\"Customer_ID\"], axis = 1, inplace=True)\n",
    "\n",
    "data = correct_missings(data, miss_pct_th = 0.33)\n",
    "\n",
    "data.to_csv('../data/data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[0])\n",
    "\n",
    "data = correct_outliers(data)\n",
    "data = data.loc[:, (data != data.iloc[0]).any()]\n",
    "\n",
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "X = data[data.columns.difference(['churn'])]\n",
    "y = data['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=77,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END classifier__C=1, classifier__max_iter=256;, score=0.555 total time=   0.1s\n",
      "[CV 2/2] END classifier__C=1, classifier__max_iter=256;, score=0.550 total time=   0.1s\n",
      "[CV 1/2] END classifier__C=1, classifier__max_iter=512;, score=0.555 total time=   0.0s\n",
      "[CV 2/2] END classifier__C=1, classifier__max_iter=512;, score=0.550 total time=   0.1s\n",
      "[CV 1/2] END classifier__C=1, classifier__max_iter=1024;, score=0.555 total time=   0.1s\n",
      "[CV 2/2] END classifier__C=1, classifier__max_iter=1024;, score=0.550 total time=   0.1s\n",
      "[CV 1/2] END classifier__C=10, classifier__max_iter=256;, score=0.555 total time=   0.1s\n",
      "[CV 2/2] END classifier__C=10, classifier__max_iter=256;, score=0.550 total time=   0.0s\n",
      "[CV 1/2] END classifier__C=10, classifier__max_iter=512;, score=0.555 total time=   0.1s\n",
      "[CV 2/2] END classifier__C=10, classifier__max_iter=512;, score=0.550 total time=   0.0s\n",
      "[CV 1/2] END classifier__C=10, classifier__max_iter=1024;, score=0.555 total time=   0.0s\n",
      "[CV 2/2] END classifier__C=10, classifier__max_iter=1024;, score=0.550 total time=   0.0s\n",
      "[CV 1/2] END classifier__C=100, classifier__max_iter=256;, score=0.555 total time=   0.0s\n",
      "[CV 2/2] END classifier__C=100, classifier__max_iter=256;, score=0.550 total time=   0.0s\n",
      "[CV 1/2] END classifier__C=100, classifier__max_iter=512;, score=0.555 total time=   0.0s\n",
      "[CV 2/2] END classifier__C=100, classifier__max_iter=512;, score=0.550 total time=   0.0s\n",
      "[CV 1/2] END classifier__C=100, classifier__max_iter=1024;, score=0.555 total time=   0.1s\n",
      "[CV 2/2] END classifier__C=100, classifier__max_iter=1024;, score=0.550 total time=   0.0s\n",
      "Los mejores parámetros para el modelo Logistic Regression son: {'classifier__C': 100, 'classifier__max_iter': 256}\n",
      " La CV score para el modelo Logistic Regression es: 0.55\n",
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.557 total time=  21.8s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.556 total time=  26.8s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.559 total time=  54.0s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.556 total time=  43.9s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.560 total time= 1.4min\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.558 total time= 1.4min\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.557 total time=  19.9s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.556 total time=  20.3s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.559 total time=  40.0s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.556 total time=  40.8s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.560 total time= 1.3min\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.558 total time= 1.4min\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.583 total time=   9.4s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.582 total time=   9.4s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.583 total time=  18.4s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.581 total time=  19.1s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.585 total time=  37.0s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.581 total time=  35.8s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.583 total time=   9.2s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.582 total time=   8.8s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.583 total time=  18.4s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.581 total time=  18.0s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.585 total time=  36.8s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.581 total time=  37.4s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.568 total time=  16.5s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.570 total time=  16.6s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.569 total time=  32.9s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.571 total time=  32.7s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.571 total time= 1.1min\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.572 total time= 1.1min\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.568 total time=  16.5s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.570 total time=  16.6s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.569 total time=  32.9s\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.571 total time=  33.1s\n",
      "[CV 1/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.571 total time= 1.1min\n",
      "[CV 2/2] END classifier__criterion=gini, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.572 total time= 1.1min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.558 total time=  27.3s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.558 total time=  31.2s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.561 total time= 1.0min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.560 total time= 1.1min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.561 total time= 2.0min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.561 total time= 2.1min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.558 total time=  31.4s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.558 total time=  31.5s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.561 total time= 1.0min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.560 total time= 1.1min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.561 total time= 2.1min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.561 total time= 2.1min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.584 total time=  12.2s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.581 total time=  12.3s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.585 total time=  25.7s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.581 total time=  24.1s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.584 total time=  49.8s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.581 total time=  48.8s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.584 total time=  12.2s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.581 total time=  12.3s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.585 total time=  25.1s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.581 total time=  23.7s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.584 total time=  49.5s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.581 total time=  45.8s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.570 total time=  23.3s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.572 total time=  22.7s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.572 total time=  46.7s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.573 total time=  47.2s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.573 total time= 1.6min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.573 total time= 1.5min\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.570 total time=  23.2s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.572 total time=  23.1s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.572 total time=  47.1s\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.573 total time=  45.0s\n",
      "[CV 1/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.573 total time= 1.6min\n",
      "[CV 2/2] END classifier__criterion=entropy, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.573 total time= 1.5min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.558 total time=  30.3s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.558 total time=  30.8s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.561 total time= 1.0min\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.560 total time= 1.0min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.561 total time= 2.0min\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.561 total time= 2.1min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.558 total time=  30.2s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=128;, score=0.558 total time=  31.3s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.561 total time=  59.2s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=256;, score=0.560 total time= 1.0min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.561 total time= 2.1min\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=None, classifier__max_features=log2, classifier__n_estimators=512;, score=0.561 total time= 2.0min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.584 total time=  11.6s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.581 total time=  11.6s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.585 total time=  24.8s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.581 total time=  23.3s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.584 total time=  49.4s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.581 total time=  46.4s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.584 total time=  13.4s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=128;, score=0.581 total time=  12.3s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.585 total time=  26.6s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=256;, score=0.581 total time=  23.4s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.584 total time=  48.5s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=10, classifier__max_features=log2, classifier__n_estimators=512;, score=0.581 total time=  47.6s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.570 total time=  23.5s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=128;, score=0.572 total time=  21.7s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.572 total time=  46.6s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=256;, score=0.573 total time=  44.7s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.573 total time= 1.6min\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=sqrt, classifier__n_estimators=512;, score=0.573 total time= 1.5min\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.570 total time=  23.7s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=128;, score=0.572 total time=  22.1s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.572 total time=  48.8s\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=256;, score=0.573 total time=  47.3s\n",
      "[CV 1/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.573 total time= 1.5min\n",
      "[CV 2/2] END classifier__criterion=log_loss, classifier__max_depth=20, classifier__max_features=log2, classifier__n_estimators=512;, score=0.573 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignacio.correcher\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores parámetros para el modelo Random Forest son: {'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__n_estimators': 256}\n",
      " La CV score para el modelo Random Forest es: 0.58\n",
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END classifier__learning_rate=0.01, classifier__n_estimators=128;, score=0.584 total time=  14.5s\n",
      "[CV 2/2] END classifier__learning_rate=0.01, classifier__n_estimators=128;, score=0.580 total time=  13.7s\n",
      "[CV 1/2] END classifier__learning_rate=0.01, classifier__n_estimators=256;, score=0.584 total time=  27.9s\n",
      "[CV 2/2] END classifier__learning_rate=0.01, classifier__n_estimators=256;, score=0.580 total time=  27.0s\n",
      "[CV 1/2] END classifier__learning_rate=0.01, classifier__n_estimators=512;, score=0.583 total time=  56.5s\n",
      "[CV 2/2] END classifier__learning_rate=0.01, classifier__n_estimators=512;, score=0.579 total time=  55.0s\n",
      "[CV 1/2] END classifier__learning_rate=0.1, classifier__n_estimators=128;, score=0.584 total time=  13.9s\n",
      "[CV 2/2] END classifier__learning_rate=0.1, classifier__n_estimators=128;, score=0.580 total time=  13.8s\n",
      "[CV 1/2] END classifier__learning_rate=0.1, classifier__n_estimators=256;, score=0.583 total time=  28.1s\n",
      "[CV 2/2] END classifier__learning_rate=0.1, classifier__n_estimators=256;, score=0.579 total time=  26.7s\n",
      "[CV 1/2] END classifier__learning_rate=0.1, classifier__n_estimators=512;, score=0.578 total time=  56.6s\n",
      "[CV 2/2] END classifier__learning_rate=0.1, classifier__n_estimators=512;, score=0.578 total time= 1.0min\n",
      "[CV 1/2] END classifier__learning_rate=1, classifier__n_estimators=128;, score=0.562 total time=  13.4s\n",
      "[CV 2/2] END classifier__learning_rate=1, classifier__n_estimators=128;, score=0.558 total time=  13.4s\n",
      "[CV 1/2] END classifier__learning_rate=1, classifier__n_estimators=256;, score=0.551 total time=  31.2s\n",
      "[CV 2/2] END classifier__learning_rate=1, classifier__n_estimators=256;, score=0.551 total time=  31.0s\n",
      "[CV 1/2] END classifier__learning_rate=1, classifier__n_estimators=512;, score=0.545 total time= 1.0min\n",
      "[CV 2/2] END classifier__learning_rate=1, classifier__n_estimators=512;, score=0.544 total time= 1.1min\n",
      "Los mejores parámetros para el modelo Gradient Boosting son: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 128}\n",
      " La CV score para el modelo Gradient Boosting es: 0.58\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV 1/2] END .........classifier__n_neighbors=5;, score=0.528 total time=   3.5s\n",
      "[CV 2/2] END .........classifier__n_neighbors=5;, score=0.530 total time=   3.5s\n",
      "[CV 1/2] END .........classifier__n_neighbors=7;, score=0.533 total time=   3.8s\n",
      "[CV 2/2] END .........classifier__n_neighbors=7;, score=0.535 total time=   2.9s\n",
      "[CV 1/2] END .........classifier__n_neighbors=9;, score=0.538 total time=   3.0s\n",
      "[CV 2/2] END .........classifier__n_neighbors=9;, score=0.539 total time=   3.0s\n",
      "Los mejores parámetros para el modelo KNN son: {'classifier__n_neighbors': 9}\n",
      " La CV score para el modelo KNN es: 0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "OHE = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = RobustScaler()\n",
    "RFC = RandomForestClassifier(random_state=77)\n",
    "\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "num_features = X_train.select_dtypes(include = ['int64', 'float64']).columns\n",
    "\n",
    "transformer = ColumnTransformer([('cat', OHE, cat_features), ('num', scaler, num_features)])\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=77),\n",
    "        'params': {\n",
    "            'classifier__C': [ 1, 10, 100],\n",
    "            'classifier__max_iter': [256, 512, 1024]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=77),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [128, 256, 512],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__criterion':['gini', 'entropy', 'log_loss'],\n",
    "            'classifier__max_features':['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=77),\n",
    "        'params': {\n",
    "            'classifier__n_estimators': [128, 256, 512],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 1]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'classifier__n_neighbors': [5, 7, 9]}\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model_dict in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessing', transformer),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=10)),\n",
    "        ('classifier', model_dict['model'])\n",
    "    ])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid=model_dict['params'], cv=2, scoring='accuracy', verbose = 3)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = {\n",
    "        'best_estimator': grid.best_estimator_,\n",
    "        'best_params': grid.best_params_,\n",
    "        'best_score': grid.best_score_\n",
    "    }\n",
    "    \n",
    "    print(f\"Los mejores parámetros para el modelo {name} son: {grid.best_params_}\")\n",
    "    print(f\" La CV score para el modelo {name} es: {grid.best_score_:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
